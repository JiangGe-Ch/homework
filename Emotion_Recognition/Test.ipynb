{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Form implementation generated from reading ui file 'D:\\大学\\毕业设计\\Emotion_Recognition\\FER_test.ui'\n",
    "#\n",
    "# Created by: PyQt5 UI code generator 5.13.2\n",
    "#\n",
    "# WARNING! All changes made in this file will be lost!\n",
    "\n",
    "import sys\n",
    "from PyQt5 import QtCore, QtGui, QtWidgets\n",
    "from PyQt5.QtWidgets import QApplication, QWidget, QFileDialog\n",
    "from PyQt5.QtCore import Qt\n",
    "from PyQt5.QtGui import QMovie\n",
    "import cv2\n",
    "import imutils\n",
    "import numpy as np\n",
    "import time\n",
    "from os import remove\n",
    "from slice_png import img as bgImg\n",
    "from base64 import b64decode\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "\n",
    "class Ui_FER_test(object):\n",
    "    def __init__(self, Window):\n",
    "        self.setupUi(Window)\n",
    "        self.retranslateUi(Window)\n",
    "        self.timer_camera = QtCore.QTimer()  # 定时器\n",
    "        self.cap = cv2.VideoCapture()  # 屏幕画面对象\n",
    "        self.CAM_NUM = 0  # 摄像头标号\n",
    "        self.model_path = 'models/48.20_my_XCEPTION.42-0.69.hdf5'  # 模型路径\n",
    "        self.slot_init()  # 槽函数设置\n",
    "\n",
    "    def setupUi(self, FER_test):\n",
    "        FER_test.setObjectName(\"FER_test\")\n",
    "        FER_test.setWindowModality(QtCore.Qt.NonModal)\n",
    "        FER_test.resize(820, 346)\n",
    "        icon = QtGui.QIcon()\n",
    "        icon.addPixmap(QtGui.QPixmap(\"D:\\\\大学\\\\毕业设计\\\\Emotion_Recognition\\\\images_test/result.png\"), QtGui.QIcon.Normal, QtGui.QIcon.Off)\n",
    "        FER_test.setWindowIcon(icon)\n",
    "        self.label_outputResult = QtWidgets.QLabel(FER_test)\n",
    "        self.label_outputResult.setGeometry(QtCore.QRect(480, 70, 300, 250))\n",
    "        self.label_outputResult.setMinimumSize(QtCore.QSize(300, 250))\n",
    "        self.label_outputResult.setMaximumSize(QtCore.QSize(300, 250))\n",
    "        font = QtGui.QFont()\n",
    "        font.setFamily(\"黑体\")\n",
    "        font.setPointSize(18)\n",
    "        self.label_outputResult.setFont(font)\n",
    "        self.label_outputResult.setObjectName(\"label_outputResult\")\n",
    "        self.label_face = QtWidgets.QLabel(FER_test)\n",
    "        self.label_face.setGeometry(QtCore.QRect(20, 30, 420, 300))\n",
    "        self.label_face.setMinimumSize(QtCore.QSize(420, 300))\n",
    "        self.label_face.setMaximumSize(QtCore.QSize(420, 300))\n",
    "        self.label_face.setText(\"\")\n",
    "        self.label_face.setObjectName(\"label_face\")\n",
    "        self.label_useTime = QtWidgets.QLabel(FER_test)\n",
    "        self.label_useTime.setGeometry(QtCore.QRect(480, 20, 61, 41))\n",
    "        font = QtGui.QFont()\n",
    "        font.setFamily(\"黑体\")\n",
    "        font.setPointSize(12)\n",
    "        self.label_useTime.setFont(font)\n",
    "        self.label_useTime.setObjectName(\"label_useTime\")\n",
    "        self.label_time = QtWidgets.QLabel(FER_test)\n",
    "        self.label_time.setGeometry(QtCore.QRect(542, 20, 71, 41))\n",
    "        font = QtGui.QFont()\n",
    "        font.setFamily(\"黑体\")\n",
    "        font.setPointSize(12)\n",
    "        self.label_time.setFont(font)\n",
    "        self.label_time.setObjectName(\"label_time\")\n",
    "        self.label_scanResult = QtWidgets.QLabel(FER_test)\n",
    "        self.label_scanResult.setGeometry(QtCore.QRect(620, 20, 91, 41))\n",
    "        font = QtGui.QFont()\n",
    "        font.setFamily(\"黑体\")\n",
    "        font.setPointSize(12)\n",
    "        self.label_scanResult.setFont(font)\n",
    "        self.label_scanResult.setObjectName(\"label_scanResult\")\n",
    "        self.label_result = QtWidgets.QLabel(FER_test)\n",
    "        self.label_result.setGeometry(QtCore.QRect(720, 20, 81, 41))\n",
    "        font = QtGui.QFont()\n",
    "        font.setFamily(\"黑体\")\n",
    "        font.setPointSize(12)\n",
    "        self.label_result.setFont(font)\n",
    "        self.label_result.setObjectName(\"label_result\")\n",
    "\n",
    "        self.retranslateUi(FER_test)\n",
    "        QtCore.QMetaObject.connectSlotsByName(FER_test)\n",
    "\n",
    "    def retranslateUi(self, FER_test):\n",
    "        _translate = QtCore.QCoreApplication.translate\n",
    "        FER_test.setWindowTitle(_translate(\"FER_test\", \"FER_test\"))\n",
    "        self.label_outputResult.setText(_translate(\"FER_test\", \"表情识别概率显示区\"))\n",
    "        self.label_useTime.setText(_translate(\"FER_test\", \"用时：\"))\n",
    "        self.label_time.setText(_translate(\"FER_test\", \"0s\"))\n",
    "        self.label_scanResult.setText(_translate(\"FER_test\", \"识别结果：\"))\n",
    "        self.label_result.setText(_translate(\"FER_test\", \"None\"))\n",
    "\n",
    "    def slot_init(self):  # 定义槽函数\n",
    "        self.open_camera()\n",
    "        self.timer_camera.timeout.connect(self.show_camera)\n",
    "\n",
    "    def open_camera(self):\n",
    "        if not self.timer_camera.isActive():  # 检查定时状态\n",
    "            flag = self.cap.open(self.CAM_NUM)  # 检查相机状态\n",
    "            if not flag:  # 相机打开失败提示\n",
    "                msg = QtWidgets.QMessageBox.warning(self.FER_test, u\"Warning\",\n",
    "                                                    u\"请检测相机与电脑是否连接正确！ \",\n",
    "                                                    buttons=QtWidgets.QMessageBox.Ok,\n",
    "                                                    defaultButton=QtWidgets.QMessageBox.Ok)\n",
    "            else:\n",
    "                # 准备运行识别程序\n",
    "                QtWidgets.QApplication.processEvents()\n",
    "                self.label_face.setText('正在启动识别系统...\\n\\nleading')\n",
    "                # 新建对象\n",
    "                self.emotion_model = Emotion_Rec(self.model_path)\n",
    "                QtWidgets.QApplication.processEvents()\n",
    "                # 打开定时器\n",
    "                self.timer_camera.start(30)\n",
    "        else:\n",
    "            # 定时器未开启，界面回复初始状态\n",
    "            self.timer_camera.stop()\n",
    "            self.cap.release()\n",
    "            self.label_face.clear()\n",
    "            self.label_outputResult.clear()\n",
    "            self.label_result.setText('None')\n",
    "            self.label_time.setText('0 s')\n",
    "\n",
    "    def show_camera(self):\n",
    "        # 定时器槽函数，每隔一段时间执行\n",
    "        flag, self.image = self.cap.read()  # 获取画面\n",
    "        self.image = cv2.flip(self.image, 1)  # 左右翻转\n",
    "\n",
    "        tmp = open('slice.png', 'wb')\n",
    "        tmp.write(b64decode(bgImg))\n",
    "        tmp.close()\n",
    "        canvas = cv2.imread('slice.png')  # 用于数据显示的背景图片\n",
    "        remove('slice.png')\n",
    "\n",
    "        time_start = time.time()  # 计时\n",
    "        # 使用模型预测\n",
    "        result = self.emotion_model.run(self.image, canvas, self.label_face, self.label_outputResult)\n",
    "        time_end = time.time()\n",
    "        # 在界面显示结果\n",
    "        self.label_result.setText(result)\n",
    "        self.label_time.setText(str(round((time_end-time_start),3))+'s')\n",
    "\n",
    "\n",
    "class Emotion_Rec:\n",
    "    def __init__(self, model_path):\n",
    "\n",
    "        # 载入数据和图片的参数\n",
    "        detection_model_path = 'haarcascade_files/haarcascade_frontalface_default.xml'\n",
    "\n",
    "        emotion_model_path = model_path\n",
    "\n",
    "        # 载入人脸检测模型\n",
    "        self.face_detection = cv2.CascadeClassifier(detection_model_path)  # 级联分类器\n",
    "\n",
    "        # 载入人脸表情识别模型\n",
    "        self.emotion_classifier = load_model(emotion_model_path, compile=False)\n",
    "        # 表情类别\n",
    "        self.EMOTIONS = [\"angry\", \"disgust\", \"fear\", \"happy\", \"sad\", \"surprise\", \"neutral\"]\n",
    "\n",
    "    def run(self, frame_in, canvas, label_face, label_result):\n",
    "        # frame_in 摄像画面或图像\n",
    "        # canvas 用于显示的背景图\n",
    "        # label_face 用于人脸显示画面的label对象\n",
    "        # label_result 用于显示结果的label对象\n",
    "\n",
    "        # 调节画面大小\n",
    "        frame = imutils.resize(frame_in, width=300)  # 缩放画面\n",
    "        # frame = cv2.resize(frame, (300,300))  # 缩放画面\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # 转为灰度图\n",
    "\n",
    "        # 检测人脸\n",
    "        faces = self.face_detection.detectMultiScale(gray, scaleFactor=1.1,\n",
    "                                                     minNeighbors=5, minSize=(30, 30),\n",
    "                                                     flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "        preds = []  # 预测的结果\n",
    "        label = None  # 预测的标签\n",
    "        (fX, fY, fW, fH) = None, None, None, None  # 人脸位置\n",
    "        if len(faces) > 0:\n",
    "            # 选择检测到的ROI最大的人脸\n",
    "            faces = sorted(faces, reverse=True, key=lambda x: (x[2] - x[0]) * (x[3] - x[1]))[0]\n",
    "            (fX, fY, fW, fH) = faces\n",
    "\n",
    "            # 从灰度图中提取感兴趣区域（ROI），将其大小转换为64*64 pixels，并为通过CNN的分类器准备ROI\n",
    "            roi = gray[fY-5:fY + fH+5, fX-5:fX + fW+5]\n",
    "            roi = cv2.resize(roi, (48, 48))\n",
    "            roi = roi.astype(\"float\") / 255.0\n",
    "            roi = img_to_array(roi)\n",
    "            roi = np.expand_dims(roi, axis=0)\n",
    "\n",
    "            # 用模型预测各分类的概率\n",
    "            preds = self.emotion_classifier.predict(roi)[0]\n",
    "            # emotion_probability = np.max(preds)  # 最大的概率\n",
    "            label = self.EMOTIONS[preds.argmax()]  # 选取最大概率的表情类\n",
    "\n",
    "        frameClone = frame.copy()  # 复制画面\n",
    "        # canvas = 255* np.ones((250, 300, 3), dtype=\"uint8\")\n",
    "        # canvas = cv2.imread('slice.png', flags=cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "        for (i, (emotion, prob)) in enumerate(zip(self.EMOTIONS, preds)):\n",
    "            # 用于显示各类别概率\n",
    "            text = \"{}: {:.2f}%\".format(emotion, prob * 100)\n",
    "\n",
    "            # 绘制表情类和对应概率的条形图\n",
    "            w = int(prob * 300)+7\n",
    "            cv2.rectangle(canvas, (7, (i * 35) + 5), (w, (i * 35) + 35), (0, 192, 255), -1)\n",
    "            cv2.putText(canvas, text, (10, (i * 35) + 23), cv2.FONT_HERSHEY_DUPLEX, 0.6, (0, 0, 0), 1)\n",
    "\n",
    "            # 圈出人脸区域并显示识别结果\n",
    "            cv2.putText(frameClone, label, (fX, fY - 10),\n",
    "                        cv2.FONT_HERSHEY_TRIPLEX, 0.6, (0, 255, 0), 1)\n",
    "            cv2.rectangle(frameClone, (fX, fY), (fX + fW, fY + fH), (255, 255, 0), 1)\n",
    "\n",
    "        # 调整画面大小与界面相适应\n",
    "        # if (frameClone.shape[0]/frameClone.shape[1]) > (280/420):\n",
    "        #     frameClone = imutils.resize(frameClone, height=280)\n",
    "        # else:\n",
    "        #     frameClone = imutils.resize(frameClone, width=420)\n",
    "        frameClone = cv2.resize(frameClone, (420, 280))\n",
    "\n",
    "        # 在Qt界面中显示人脸\n",
    "        show = cv2.cvtColor(frameClone, cv2.COLOR_BGR2RGB)\n",
    "        showImage = QtGui.QImage(show.data, show.shape[1], show.shape[0], QtGui.QImage.Format_RGB888)\n",
    "        label_face.setPixmap(QtGui.QPixmap.fromImage(showImage))\n",
    "        QtWidgets.QApplication.processEvents()\n",
    "\n",
    "        # 在显示结果的label中显示结果\n",
    "        show = cv2.cvtColor(canvas, cv2.COLOR_BGR2RGB)\n",
    "        showImage = QtGui.QImage(show.data, show.shape[1], show.shape[0], QtGui.QImage.Format_RGB888)\n",
    "        label_result.setPixmap(QtGui.QPixmap.fromImage(showImage))\n",
    "\n",
    "        return(label)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app = QApplication(sys.argv)\n",
    "\n",
    "    window = QWidget()\n",
    "    ui = Ui_FER_test(window)\n",
    "\n",
    "    window.show()\n",
    "    exit(app.exec_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
